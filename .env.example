# Basic Configuration
BOT_TOKEN=your_telegram_bot_token_here
GITHUB_TOKEN=your_github_token_here

# LLM Provider Configuration
# Options: openai, together, openrouter
LLM_PROVIDER=openrouter

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4

# Together AI Configuration
TOGETHER_API_KEY=your_together_api_key_here
TOGETHER_MODEL=meta-llama/Llama-3.3-70B-Instruct-Turbo

# OpenRouter Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=openai/gpt-4o

# Security Configuration
AUTHORIZED_TELEGRAM_USERS=XXXXXXXXXX

# Rate Limiting (optional)
MAX_REQUESTS_PER_HOUR=10
MAX_REQUESTS_PER_DAY=50

# Chat Context Configuration (optional)
CHAT_CONTEXT_MAX_MESSAGES=20

# Repository Context Configuration (optional)
REPO_CONTEXT_MAX_TOKENS=15000
REPO_CONTEXT_MAX_FILES=20
REPO_CONTEXT_MAX_FILE_SIZE=10000
REPO_CONTEXT_DEPTH=3

# Git Strategy (optional)
# Options: direct, branch
GIT_STRATEGY=branch

# LLM Configuration (optional)
LLM_MAX_TOKENS=8000
LLM_TEMPERATURE=0.1
LLM_MAX_RETRIES=2
LLM_RETRY_DELAY=5.0
LLM_TIMEOUT_SECONDS=300
LLM_STREAMING=false
LLM_STREAMING_TIMEOUT_SECONDS=600
DEBUG_LLM=false

